#!/usr/bin/env python

import json

#import create_pipeline
import streams
import tracks
import users

from options import SetPipelineOptions

spo = SetPipelineOptions()
spo.options = spo.set_pipeline()
options = spo.set_google_cloud_options(spo.google_cloud, spo.pipeline)
options = spo.set_runner(spo.options, spo.config.get('standard').get('runner'))
pipeline = create_pipeline.CreatePipeline(options)
print(pipeline)


u = (p
     | 'read users' >> ab.io.ReadFromText('gs://abbynormal/users.gz')
     | 'map users' >> ab.Map(lambda user_id: (json.loads(user_id).get('user_id'), json.loads(user_id)))
)

t = (p
     | 'read tracks' >> ab.io.ReadFromText('gs://abbynormal/tracks.gz')
     | 'map tracks' >> ab.Map(lambda track_id: (json.loads(track_id).get('track_id'), json.loads(track_id)))
)

s = (({'streams':s,'users':u}) | 'co group by key users' >> ab.CoGroupByKey())
s = s | 'process users' >> ab.ParDo(ProcessUsers())
s = s | 'remap streams' >> ab.Map(lambda sid: (sid.get('track_id'), sid))
s = (({'streams':s, 'tracks':t}) | 'co group by key tracks' >> ab.CoGroupByKey(pipeline=p))
s = s | 'process tracks' >> ab.ParDo(ProcessTracks())
#s = s | 'print st' >> ab.Map(lambda sid: print(sid))
s = s | 'output' >> ab.io.WriteToText('gs://abbynormal/dnormal')

p.run()
